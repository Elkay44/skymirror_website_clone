---
sidebar_position: 8
title: "Customer Discovery Playbook"
---

# Skymirror Customer Discovery & Validation Playbook

## Executive Summary

This playbook establishes Skymirror's approach to customer discovery, problem validation, and market testing. It provides frameworks for validating assumptions, testing willingness to pay, and refining messaging based on customer evidence for all Skymirror products: **CheckMet** (AI attendance), **Traquiva** (AI learning platform), **Software Solutions**, and **Skymirror Academy**.

---

## Part 1: Problem Validation

### 1.1 Problem Statement

#### Current Problem Hypothesis

**For:** Enterprise HR and Operations leaders (200-5,000 employees)

**Who:** Struggle with manual attendance tracking, time fraud, and compliance documentation

**Our Product:** CheckMet AI-powered attendance management

**Solves:** The problem of inaccurate, time-consuming, and fraud-prone attendance tracking

**Unlike:** Traditional time clocks, badge systems, and manual spreadsheets

**Our Solution:** Provides 99.9% accurate facial recognition, real-time analytics, and seamless HRIS integration

### 1.2 Problem Validation Framework

#### Key Questions to Validate

| Question | Hypothesis | Validation Method | Status |
|----------|------------|-------------------|--------|
| Is this a real problem? | Yes, costs â‚¬200K+/year | Customer interviews | â¬œ Pending |
| How painful is it? | Very painful (top 3 priority) | Pain ranking exercise | â¬œ Pending |
| How often does it occur? | Daily | Usage frequency questions | â¬œ Pending |
| Who experiences it most? | HR Directors, COOs | Persona validation | â¬œ Pending |
| What's the current solution? | Manual/badge systems | Competitive analysis | â¬œ Pending |
| Why hasn't it been solved? | Tech limitations, cost | Root cause analysis | â¬œ Pending |

#### Problem Interview Script

```markdown
## Problem Discovery Interview

### Introduction (5 min)
"Thank you for taking the time to speak with me. I'm researching how companies manage employee attendance and time tracking. I'm not here to sell anything - I just want to understand your experience."

### Current State (10 min)
1. Can you walk me through how you currently track employee attendance?
2. What tools or systems do you use?
3. How many people are involved in this process?
4. How much time does your team spend on attendance-related tasks each week?

### Pain Points (15 min)
5. What are the biggest challenges you face with your current approach?
6. Can you give me a specific example of when this caused a problem?
7. How often do these issues occur?
8. What's the impact when things go wrong? (time, money, stress)
9. On a scale of 1-10, how painful is this problem for you?

### Attempted Solutions (10 min)
10. What have you tried to solve these problems?
11. Why didn't those solutions work?
12. What would an ideal solution look like?
13. If you could wave a magic wand, what would change?

### Prioritization (5 min)
14. Where does this rank among your top priorities?
15. What would need to happen for this to become a higher priority?
16. Who else in your organization cares about this problem?

### Wrap-up (5 min)
17. Is there anything else about attendance management I should know?
18. Would you be open to seeing a solution if we built one?
19. Who else should I talk to about this?
```

### 1.3 Problem Validation Evidence

#### Evidence Collection Template

```markdown
## Problem Validation Evidence

### Interview Summary
**Date:** [Date]
**Company:** [Company Name]
**Interviewee:** [Name, Title]
**Company Size:** [Employees]
**Industry:** [Industry]

### Problem Confirmation
| Problem | Confirmed? | Severity (1-10) | Frequency | Quote |
|---------|------------|-----------------|-----------|-------|
| Manual tracking errors | â¬œ Yes â¬œ No | /10 | | "" |
| Time fraud/buddy punching | â¬œ Yes â¬œ No | /10 | | "" |
| Compliance documentation | â¬œ Yes â¬œ No | /10 | | "" |
| Integration challenges | â¬œ Yes â¬œ No | /10 | | "" |
| Lack of real-time data | â¬œ Yes â¬œ No | /10 | | "" |

### Quantified Impact
- Hours spent on attendance admin per week: ___
- Estimated annual cost of current approach: â‚¬___
- Estimated losses from errors/fraud: â‚¬___
- Number of people involved: ___

### Current Solution
- Primary tool/method: ___
- Satisfaction level (1-10): ___
- Main complaints: ___

### Key Quotes
> "[Quote 1]"
> "[Quote 2]"
> "[Quote 3]"

### Insights
1. [Insight 1]
2. [Insight 2]
3. [Insight 3]
```

### 1.4 Problem Validation Scorecard

| Criteria | Target | Actual | Status |
|----------|--------|--------|--------|
| Interviews completed | 20+ | | â¬œ |
| Problem confirmed rate | 80%+ | | â¬œ |
| Average pain score | 7+/10 | | â¬œ |
| Willingness to solve | 70%+ | | â¬œ |
| Budget available | 60%+ | | â¬œ |

---

## Part 2: Assumption Testing

### 2.1 Assumption Mapping

#### Critical Assumptions

| # | Assumption | Risk Level | Test Method | Status |
|---|------------|------------|-------------|--------|
| 1 | Enterprises lose â‚¬200K+/year on attendance issues | HIGH | Customer interviews | â¬œ |
| 2 | HR Directors are the primary decision makers | HIGH | Sales process analysis | â¬œ |
| 3 | 99.9% accuracy is a meaningful differentiator | HIGH | Competitive testing | â¬œ |
| 4 | Customers will pay â‚¬1-2/user/month | HIGH | Pricing tests | â¬œ |
| 5 | Implementation can be done in 2-4 weeks | MEDIUM | Pilot tracking | â¬œ |
| 6 | HRIS integration is a must-have | MEDIUM | Feature prioritization | â¬œ |
| 7 | Mobile check-in is important for hybrid work | MEDIUM | Usage analytics | â¬œ |
| 8 | Customers prefer cloud over on-premise | LOW | Preference surveys | â¬œ |

### 2.2 Assumption Testing Framework

#### Test Design Template

```markdown
## Assumption Test Design

### Assumption
[Clear statement of the assumption]

### Why It Matters
[Impact if assumption is wrong]

### Test Method
[How we will test this]

### Success Criteria
[What would validate the assumption]

### Failure Criteria
[What would invalidate the assumption]

### Timeline
[When we will have results]

### Resources Needed
[What we need to run the test]

### Results
[Actual results when complete]

### Conclusion
â¬œ Validated | â¬œ Invalidated | â¬œ Inconclusive

### Next Steps
[Actions based on results]
```

#### Assumption Test: Pricing

```markdown
## Assumption Test: Pricing

### Assumption
Customers will pay â‚¬1-2/user/month for CheckMet

### Why It Matters
Pricing directly impacts unit economics and viability

### Test Method
1. Van Westendorp price sensitivity survey (n=50)
2. A/B test pricing pages (â‚¬1 vs â‚¬1.50 vs â‚¬2)
3. Negotiation tracking in sales process

### Success Criteria
- 60%+ find â‚¬1-2/user "acceptable"
- Conversion rate similar across price points
- Under 20% of deals lost on price

### Failure Criteria
- Under 40% find â‚¬1-2/user "acceptable"
- Significant conversion drop at higher prices
- Over 40% of deals lost on price

### Timeline
4 weeks

### Results
[To be completed]
```

### 2.3 Riskiest Assumption Test (RAT)

#### Current RAT Priority

**Assumption:** Enterprise customers will pay â‚¬1-2/user/month for AI attendance

**Why Riskiest:** 
- Directly impacts revenue model viability
- No historical data to validate
- Competitors have different pricing models

**Test Plan:**
1. Week 1-2: Price sensitivity survey with 50 prospects
2. Week 3-4: A/B test landing pages with different prices
3. Week 5-6: Track actual negotiation outcomes

**Decision Point:**
- If validated: Proceed with â‚¬12/user base pricing
- If invalidated: Explore alternative pricing models (per-location, flat fee)

---

## Part 3: Value Proposition

### 3.1 Value Proposition Canvas

#### Customer Profile

**Customer Jobs:**
- Track employee attendance accurately
- Process payroll without errors
- Ensure labor law compliance
- Manage remote/hybrid workforce
- Report on workforce metrics

**Pains:**
- Manual tracking is time-consuming (10+ hrs/week)
- Errors cause payroll disputes
- Fraud costs â‚¬50K+/year
- Compliance audits are stressful
- No real-time visibility

**Gains:**
- Accurate, automated tracking
- Reduced administrative burden
- Cost savings from fraud prevention
- Audit-ready documentation
- Real-time workforce insights

#### Value Map

**Products & Services:**
- AI facial recognition attendance
- Real-time analytics dashboard
- HRIS/payroll integrations
- Mobile app for remote check-in
- Compliance reporting

**Pain Relievers:**
- 99.9% accuracy eliminates errors
- Automation saves 10+ hrs/week
- Fraud detection prevents losses
- Audit-ready reports reduce stress
- Real-time data enables decisions

**Gain Creators:**
- Instant attendance visibility
- Seamless payroll integration
- Employee self-service
- Predictive analytics
- Multi-location management

### 3.2 Value Proposition Statement

#### Template
> For [target customer] who [statement of need], [product name] is a [product category] that [key benefit]. Unlike [competition], our product [key differentiator].

#### Skymirror Value Proposition
> For enterprise HR and Operations leaders who struggle with inaccurate, time-consuming attendance management, CheckMet is an AI-powered attendance platform that eliminates 95% of administrative burden while achieving 99.9% accuracy. Unlike traditional time clocks and badge systems, CheckMet uses facial recognition AI that prevents fraud, integrates seamlessly with existing HRIS, and provides real-time workforce analytics.

### 3.3 Value Proposition Testing

#### Message Testing Framework

| Message Variant | Target Audience | Channel | Metric | Result |
|-----------------|-----------------|---------|--------|--------|
| "99.9% accurate attendance" | HR Directors | LinkedIn | CTR | |
| "Eliminate time fraud" | COOs | Email | Reply rate | |
| "Save 10 hours/week" | HR Managers | Landing page | Conversion | |
| "Real-time workforce visibility" | Operations | Webinar | Registration | |

#### A/B Test Template

```markdown
## Value Proposition A/B Test

### Hypothesis
[Message A] will outperform [Message B] for [audience]

### Test Setup
- **Audience:** [Description]
- **Sample Size:** [Number per variant]
- **Duration:** [Days/weeks]
- **Channel:** [Where tested]

### Variants
**A (Control):** [Message]
**B (Test):** [Message]

### Primary Metric
[What we're measuring]

### Results
| Variant | Impressions | Clicks | CTR | Conversions | Conv Rate |
|---------|-------------|--------|-----|-------------|-----------|
| A | | | | | |
| B | | | | | |

### Statistical Significance
[Confidence level]

### Winner
[A or B]

### Learnings
[What we learned]

### Next Steps
[Actions to take]
```

---

## Part 4: Market Sizing

### 4.1 Bottom-Up Market Sizing

#### TAM Calculation

```
Total Addressable Market (TAM)
= Total enterprises globally Ã— % with attendance needs Ã— Average deal size

= 500,000 enterprises (200+ employees globally)
Ã— 80% (need attendance management)
Ã— â‚¬50,000 (average annual contract value)
= â‚¬20 billion
```

#### SAM Calculation

```
Serviceable Available Market (SAM)
= TAM Ã— % in target geography Ã— % in target industries

= â‚¬20 billion
Ã— 15% (Europe)
Ã— 60% (target industries: manufacturing, healthcare, education, services)
= â‚¬1.8 billion
```

#### SOM Calculation

```
Serviceable Obtainable Market (SOM)
= SAM Ã— Realistic market share in 5 years

= â‚¬1.8 billion
Ã— 2% (achievable market share)
= â‚¬36 million
```

### 4.2 Market Segment Analysis

| Segment | # Companies | Avg Deal Size | Market Size | Priority |
|---------|-------------|---------------|-------------|----------|
| Large Enterprise (5000+) | 5,000 | â‚¬200,000 | â‚¬1B | Medium |
| Mid-Enterprise (1000-5000) | 25,000 | â‚¬75,000 | â‚¬1.9B | High |
| Mid-Market (200-1000) | 100,000 | â‚¬25,000 | â‚¬2.5B | High |
| SMB (50-200) | 500,000 | â‚¬8,000 | â‚¬4B | Low |

### 4.3 Early Adopter Segment

#### Ideal Early Adopter Profile

| Attribute | Criteria | Rationale |
|-----------|----------|-----------|
| Size | 200-1,000 employees | Complex enough to need solution, fast decision-making |
| Industry | Manufacturing, Healthcare | High compliance needs, shift workers |
| Geography | Hungary, DACH | Local presence, language capability |
| Tech Maturity | Moderate-high | Willing to adopt new technology |
| Pain Level | Acute | Recent compliance issue or growth |
| Champion | HR Director with budget | Can make decisions quickly |

#### Early Adopter Identification

| Signal | Where to Find | Priority |
|--------|---------------|----------|
| Recent funding/growth | Crunchbase, news | High |
| Hiring HR roles | LinkedIn, job boards | High |
| Compliance issues | News, industry reports | High |
| Digital transformation | Case studies, events | Medium |
| New locations/expansion | News, LinkedIn | Medium |

---

## Part 5: Competitive Analysis

### 5.1 Competitive Landscape

#### Direct Competitors

| Competitor | Positioning | Strengths | Weaknesses | Pricing |
|------------|-------------|-----------|------------|---------|
| [Competitor 1] | Enterprise time tracking | Brand, integrations | Outdated tech, expensive | â‚¬15-25/user |
| [Competitor 2] | Biometric attendance | Hardware + software | Complex implementation | â‚¬10-20/user + hardware |
| [Competitor 3] | HR suite with attendance | All-in-one | Attendance is afterthought | â‚¬8-15/user |

#### Indirect Competitors

| Alternative | When Chosen | Strengths | Weaknesses |
|-------------|-------------|-----------|------------|
| Manual/spreadsheets | Low budget | Free, familiar | Error-prone, time-consuming |
| Badge systems | Simple needs | Low cost, simple | Fraud-prone, no analytics |
| Generic time clocks | Basic tracking | Cheap | No integration, limited features |
| Do nothing | Low priority | No cost | Problems persist |

### 5.2 Competitive Positioning

#### Positioning Matrix

```
                    HIGH ACCURACY
                         â”‚
                         â”‚
    CheckMet â—           â”‚           â— [Competitor 1]
                         â”‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    LOW COST             â”‚           HIGH COST
                         â”‚
                         â”‚
    â— Manual             â”‚           â— [Competitor 2]
                         â”‚
                    LOW ACCURACY
```

#### Differentiation Points

| Dimension | CheckMet | Competitor Average | Advantage |
|-----------|----------|-------------------|-----------|
| Accuracy | 99.9% | 85-95% | +5-15% |
| Implementation | 2-4 weeks | 8-12 weeks | 3x faster |
| Integrations | 50+ | 10-20 | 2.5x more |
| Mobile capability | Full | Limited | Superior |
| AI/Analytics | Advanced | Basic | Superior |
| Pricing | â‚¬1-2/user | â‚¬10-25/user | 20-40% lower |

### 5.3 Competitive Intelligence

#### Win/Loss Analysis Template

```markdown
## Win/Loss Analysis

### Deal Information
- **Company:** [Name]
- **Deal Size:** â‚¬[Amount]
- **Outcome:** â¬œ Won | â¬œ Lost
- **Competitor:** [Name]
- **Sales Cycle:** [Days]

### Decision Factors
| Factor | Importance (1-5) | Our Score | Competitor Score |
|--------|------------------|-----------|------------------|
| Price | | | |
| Features | | | |
| Ease of use | | | |
| Integration | | | |
| Support | | | |
| Brand/trust | | | |

### Key Reasons for Outcome
1. [Reason 1]
2. [Reason 2]
3. [Reason 3]

### Customer Quotes
> "[Quote about decision]"

### Learnings
1. [Learning 1]
2. [Learning 2]

### Actions
- [ ] [Action to improve]
```

---

## Part 6: Willingness to Pay

### 6.1 Price Sensitivity Research

#### Van Westendorp Method

**Questions:**
1. At what price would you consider CheckMet to be so expensive that you would not consider buying it? (Too Expensive)
2. At what price would you consider CheckMet to be priced so low that you would question its quality? (Too Cheap)
3. At what price would you consider CheckMet to be getting expensive, but you still might consider it? (Expensive)
4. At what price would you consider CheckMet to be a bargainâ€”a great buy for the money? (Cheap)

#### Results Template

| Price Point | Too Cheap | Cheap | Expensive | Too Expensive |
|-------------|-----------|-------|-----------|---------------|
| â‚¬5/user | X% | X% | X% | X% |
| â‚¬8/user | X% | X% | X% | X% |
| â‚¬10/user | X% | X% | X% | X% |
| â‚¬12/user | X% | X% | X% | X% |
| â‚¬15/user | X% | X% | X% | X% |
| â‚¬20/user | X% | X% | X% | X% |

**Optimal Price Point:** â‚¬[X]/user
**Acceptable Price Range:** â‚¬[X] - â‚¬[X]/user

### 6.2 Commitment Signals

#### Signal Hierarchy

| Signal | Strength | Example | Weight |
|--------|----------|---------|--------|
| Signed contract | Strongest | Paid subscription | 100% |
| Payment received | Very strong | Pilot fee paid | 90% |
| Letter of Intent | Strong | Signed LOI | 70% |
| Verbal commitment | Moderate | "We'll buy when ready" | 40% |
| Demo request | Weak | Requested demo | 20% |
| Content download | Weakest | Downloaded whitepaper | 5% |

#### Commitment Tracking

| Company | Contact | Signal | Date | Value | Next Step |
|---------|---------|--------|------|-------|-----------|
| [Company 1] | [Name] | LOI signed | [Date] | â‚¬[X] | Contract |
| [Company 2] | [Name] | Pilot paid | [Date] | â‚¬[X] | Expand |
| [Company 3] | [Name] | Verbal commit | [Date] | â‚¬[X] | LOI |

### 6.3 Pilot Program

#### Pilot Structure

| Element | Details |
|---------|---------|
| Duration | 4-8 weeks |
| Users | 50-200 employees |
| Fee | â‚¬2,000-5,000 (credited to annual) |
| Success Criteria | 95%+ adoption, &lt;5 support tickets |
| Conversion Target | 70%+ to annual subscription |

#### Pilot Agreement Template

```markdown
## CheckMet Pilot Agreement

### Parties
- Skymirror Kft. ("Provider")
- [Company Name] ("Customer")

### Pilot Scope
- Duration: [X] weeks
- Users: Up to [X] employees
- Locations: [X] site(s)
- Features: Full CheckMet [Edition] access

### Pilot Fee
- Amount: â‚¬[X]
- Payment: Due upon signing
- Credit: Applied to annual subscription if converted

### Success Criteria
- [ ] 95%+ daily active usage
- [ ] &lt;5 support tickets
- [ ] Positive feedback from key stakeholders
- [ ] Integration with [HRIS] successful

### Conversion Terms
- Annual subscription: â‚¬[X]/user/year
- Pilot fee credited in full
- Decision deadline: [Date]

### Signatures
[Signature blocks]
```

---

## Part 7: Messaging & Positioning

### 7.1 Customer Language Database

#### Collected Phrases

| Theme | Customer Language | Source | Frequency |
|-------|-------------------|--------|-----------|
| Pain | "Nightmare to manage" | Interview | 5x |
| Pain | "Constant headache" | Interview | 3x |
| Pain | "Waste of time" | Survey | 8x |
| Need | "Just want it to work" | Interview | 4x |
| Need | "Need real-time visibility" | Interview | 6x |
| Value | "Game changer" | Customer | 2x |
| Value | "Finally solved" | Customer | 3x |

### 7.2 Message Testing Results

| Message | Channel | Audience | CTR/Response | Winner? |
|---------|---------|----------|--------------|---------|
| "99.9% accurate attendance" | LinkedIn | HR | 2.3% | â¬œ |
| "Eliminate buddy punching" | LinkedIn | HR | 3.1% | âœ… |
| "Save 10 hours/week" | Email | Ops | 4.2% | âœ… |
| "Real-time workforce data" | Email | Ops | 2.8% | â¬œ |

### 7.3 Refined Messaging Framework

#### By Persona

| Persona | Primary Message | Supporting Points |
|---------|-----------------|-------------------|
| HR Director | "Eliminate attendance admin headaches" | Accuracy, compliance, time savings |
| COO | "Real-time workforce visibility" | Analytics, multi-location, efficiency |
| CFO | "Reduce payroll errors and fraud" | ROI, cost savings, accuracy |
| IT Director | "Seamless integration, enterprise security" | APIs, SSO, GDPR compliance |

#### By Stage

| Buyer Stage | Message Focus | Content Type |
|-------------|---------------|--------------|
| Awareness | Problem education | Blog, social |
| Consideration | Solution comparison | Webinar, guide |
| Decision | Proof and ROI | Case study, demo |
| Retention | Value reinforcement | QBR, newsletter |

---

## Part 8: Validation Tracking

### 8.1 Validation Dashboard

```markdown
## Customer Discovery Dashboard - [Date]

### Interview Progress
| Type | Target | Completed | Insights |
|------|--------|-----------|----------|
| Problem discovery | 20 | X | X |
| Solution validation | 15 | X | X |
| Pricing research | 30 | X | X |
| Win/loss analysis | 10 | X | X |

### Key Metrics
| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| Problem confirmed | 80% | X% | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |
| Solution fit | 70% | X% | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |
| Willingness to pay | 60% | X% | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |
| Pilot conversions | 70% | X% | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |

### Assumption Status
| Assumption | Status | Confidence |
|------------|--------|------------|
| Problem is real | â¬œ Validated | High/Med/Low |
| ICP is correct | â¬œ Validated | High/Med/Low |
| Pricing works | â¬œ Testing | High/Med/Low |
| Differentiation matters | â¬œ Testing | High/Med/Low |

### Top Insights This Week
1. [Insight 1]
2. [Insight 2]
3. [Insight 3]

### Actions
- [ ] [Action 1] - Owner - Due
- [ ] [Action 2] - Owner - Due
```

### 8.2 Evidence Repository

```
ğŸ“ Customer Discovery
â”œâ”€â”€ ğŸ“ Interviews
â”‚   â”œâ”€â”€ ğŸ“ Problem Discovery
â”‚   â”œâ”€â”€ ğŸ“ Solution Validation
â”‚   â””â”€â”€ ğŸ“ Pricing Research
â”œâ”€â”€ ğŸ“ Surveys
â”‚   â”œâ”€â”€ Price Sensitivity
â”‚   â””â”€â”€ Feature Prioritization
â”œâ”€â”€ ğŸ“ Competitive
â”‚   â”œâ”€â”€ Win-Loss Analysis
â”‚   â””â”€â”€ Competitor Research
â”œâ”€â”€ ğŸ“ Pilots
â”‚   â”œâ”€â”€ Agreements
â”‚   â””â”€â”€ Results
â””â”€â”€ ğŸ“ Analysis
    â”œâ”€â”€ Assumption Tests
    â””â”€â”€ Validation Reports
```

---

*Document Version: 1.0*
*Last Updated: December 2024*
*Owner: Product / CEO*
*Review Cycle: Monthly*
